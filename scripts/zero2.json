{
  "train_micro_batch_size_per_gpu": 16,
  "gradient_accumulation_steps": 1,
  "train_batch_size": 112,

  "bf16": { "enabled": true },

  "zero_optimization": {
    "stage": 2,
    "overlap_comm": true,
    "contiguous_gradients": true,

    "reduce_bucket_size": 50000000,
    "allgather_bucket_size": 50000000,
    "sub_group_size": 1000000000
  },

  "gradient_clipping": 1.0,
  "wall_clock_breakdown": false
}